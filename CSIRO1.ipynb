{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6a2ae9bb8f44693bb2c2670a9156b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e892bf9da0964e01a231afdf83d2eb85",
              "IPY_MODEL_6e13feb8bd3a4699815c77b3a60b6573",
              "IPY_MODEL_9d2f8e0de6b54e0291b5f0874aa15c69"
            ],
            "layout": "IPY_MODEL_13aef4d8c5bb4c1bb5647dbe07819c61"
          }
        },
        "e892bf9da0964e01a231afdf83d2eb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677bf4adcae94088a49542435935fe81",
            "placeholder": "​",
            "style": "IPY_MODEL_119d9edc776d4e4bb2177b98467794ab",
            "value": "model.safetensors: 100%"
          }
        },
        "6e13feb8bd3a4699815c77b3a60b6573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca9092a6bfc4247a8689daf1d974a86",
            "max": 1712935120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f174b752098647c69ef3f98167226a23",
            "value": 1712935120
          }
        },
        "9d2f8e0de6b54e0291b5f0874aa15c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1749a36621674a8690ed9d7ee50e0b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf8707f80ca40d09028ab0b8b42f4db",
            "value": " 1.71G/1.71G [00:02&lt;00:00, 764MB/s]"
          }
        },
        "13aef4d8c5bb4c1bb5647dbe07819c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677bf4adcae94088a49542435935fe81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119d9edc776d4e4bb2177b98467794ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dca9092a6bfc4247a8689daf1d974a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f174b752098647c69ef3f98167226a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1749a36621674a8690ed9d7ee50e0b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf8707f80ca40d09028ab0b8b42f4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMSIJpv2fqLj",
        "outputId": "8c0c7474-99b7-412a-b480-912fb04e78e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "BASE_DIR: /content/drive/MyDrive/CSIRO\n",
            "✅ Dataset paths look good.\n",
            "✅ Run directory created at: /content/drive/MyDrive/CSIRO/runs/run_001\n",
            "Folders:\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/checkpoints/modelA_dinov2\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/checkpoints/modelB_siglip\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/oof\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/preds_test\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/submissions\n",
            " - /content/drive/MyDrive/CSIRO/runs/run_001/logs\n",
            "\n",
            "Torch CUDA available: True\n",
            "GPU name: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "===== nvidia-smi =====\n",
            "Sun Dec 28 20:56:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             43W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# BLOCK 1: Runtime + Storage\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# (Notebook) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base dataset folder in your Drive\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/CSIRO\")\n",
        "\n",
        "# Sanity check: confirm expected files/folders exist\n",
        "expected = [\n",
        "    BASE_DIR / \"train.csv\",\n",
        "    BASE_DIR / \"test.csv\",\n",
        "    BASE_DIR / \"sample_submission.csv\",\n",
        "    BASE_DIR / \"train\",\n",
        "    BASE_DIR / \"test\",\n",
        "]\n",
        "missing = [str(p) for p in expected if not p.exists()]\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "if missing:\n",
        "    print(\"❌ Missing these paths:\")\n",
        "    for m in missing:\n",
        "        print(\"  -\", m)\n",
        "    raise FileNotFoundError(\"Fix missing dataset paths in Google Drive.\")\n",
        "else:\n",
        "    print(\"✅ Dataset paths look good.\")\n",
        "\n",
        "# Create run folder structure (persisted on Drive)\n",
        "RUN_DIR = BASE_DIR / \"runs\" / \"run_001\"\n",
        "\n",
        "DIRS_TO_CREATE = [\n",
        "    RUN_DIR / \"checkpoints\" / \"modelA_dinov2\",\n",
        "    RUN_DIR / \"checkpoints\" / \"modelB_siglip\",\n",
        "    RUN_DIR / \"oof\",\n",
        "    RUN_DIR / \"preds_test\",\n",
        "    RUN_DIR / \"submissions\",\n",
        "    RUN_DIR / \"logs\",\n",
        "]\n",
        "\n",
        "for d in DIRS_TO_CREATE:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"✅ Run directory created at:\", RUN_DIR)\n",
        "print(\"Folders:\")\n",
        "for d in DIRS_TO_CREATE:\n",
        "    print(\" -\", d)\n",
        "\n",
        "# (Notebook) Confirm GPU is available (A100 expected)\n",
        "import torch\n",
        "print(\"\\nTorch CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"❌ No GPU detected. Go to Runtime → Change runtime type → GPU.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    import subprocess\n",
        "    out = subprocess.check_output([\"nvidia-smi\"], text=True)\n",
        "    print(\"\\n===== nvidia-smi =====\")\n",
        "    print(out)\n",
        "except Exception as e:\n",
        "    print(\"nvidia-smi not available:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 2 Load + verify dataset quickly\n",
        "import os, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "assert \"BASE_DIR\" in globals() and \"RUN_DIR\" in globals(), \"Run Block 1 first.\"\n",
        "TRAIN_CSV, TEST_CSV, SUB_CSV = BASE_DIR/\"train.csv\", BASE_DIR/\"test.csv\", BASE_DIR/\"sample_submission.csv\"\n",
        "train_long, test_df, sub_df = pd.read_csv(TRAIN_CSV), pd.read_csv(TEST_CSV), pd.read_csv(SUB_CSV)\n",
        "\n",
        "TARGETS = [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\",\"GDM_g\",\"Dry_Total_g\"]\n",
        "WEIGHTS = {\"Dry_Green_g\":0.1,\"Dry_Dead_g\":0.1,\"Dry_Clover_g\":0.1,\"GDM_g\":0.2,\"Dry_Total_g\":0.5}\n",
        "\n",
        "# Required columns\n",
        "for c in [\"sample_id\",\"image_path\",\"target_name\",\"target\"]:\n",
        "    if c not in train_long.columns: raise ValueError(f\"train.csv missing {c}\")\n",
        "for c in [\"sample_id\",\"image_path\",\"target_name\"]:\n",
        "    if c not in test_df.columns: raise ValueError(f\"test.csv missing {c}\")\n",
        "\n",
        "# True image id from composite sample_id (IDxxxx__Target)\n",
        "train_long[\"image_id\"] = train_long[\"sample_id\"].astype(str).str.split(\"__\").str[0]\n",
        "test_df[\"image_id\"] = test_df[\"sample_id\"].astype(str).str.split(\"__\").str[0]\n",
        "\n",
        "print(\"Shapes:\", train_long.shape, test_df.shape, sub_df.shape)\n",
        "print(\"Train targets:\", sorted(train_long[\"target_name\"].unique()))\n",
        "print(\"Test targets :\", sorted(test_df[\"target_name\"].unique()))\n",
        "\n",
        "extra_tr = set(train_long[\"target_name\"].unique()) - set(TARGETS)\n",
        "extra_te = set(test_df[\"target_name\"].unique()) - set(TARGETS)\n",
        "if extra_tr: print(\"⚠️ Unexpected train target_name:\", extra_tr)\n",
        "if extra_te: print(\"⚠️ Unexpected test target_name :\", extra_te)\n",
        "\n",
        "# Long-format sanity\n",
        "print(\"Unique images:\", train_long[\"image_id\"].nunique(),\n",
        "      \"| median targets/image:\", int(train_long.groupby(\"image_id\")[\"target_name\"].nunique().median()))\n",
        "\n",
        "# Path sanity (sample 20)\n",
        "np.random.seed(1947)\n",
        "paths = train_long[\"image_path\"].dropna().sample(min(20, len(train_long)), random_state=1947).tolist()\n",
        "missing = [p for p in paths if not (BASE_DIR/p).exists()]\n",
        "print(\"Missing sampled image paths:\", len(missing))\n",
        "if missing: print(\"Example missing:\", missing[0], \"->\", BASE_DIR/missing[0])\n",
        "\n",
        "# Quick target ranges\n",
        "stats = train_long.groupby(\"target_name\")[\"target\"].agg([\"count\",\"min\",\"median\",\"max\"]).reindex(TARGETS)\n",
        "print(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuRBOXvdwiHU",
        "outputId": "c7f89cd2-2beb-430a-9fa0-9851c8325a32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (1785, 10) (5, 4) (5, 2)\n",
            "Train targets: ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
            "Test targets : ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
            "Unique images: 357 | median targets/image: 5\n",
            "Missing sampled image paths: 0\n",
            "              count   min   median       max\n",
            "target_name                                 \n",
            "Dry_Green_g     357  0.00  20.8000  157.9836\n",
            "Dry_Dead_g      357  0.00   7.9809   83.8407\n",
            "Dry_Clover_g    357  0.00   1.4235   71.7865\n",
            "GDM_g           357  1.04  27.1082  157.9836\n",
            "Dry_Total_g     357  1.04  40.3000  185.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 3  Pivot long->wide (1 row per image_id) + keep metadata\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "assert \"train_long\" in globals(), \"Run Block 2 first.\"\n",
        "\n",
        "META_COLS = [\"image_id\",\"image_path\",\"Sampling_Date\",\"State\",\"Species\",\"Pre_GSHH_NDVI\",\"Height_Ave_cm\"]\n",
        "META_COLS = [c for c in META_COLS if c in train_long.columns]\n",
        "\n",
        "meta = train_long[META_COLS].drop_duplicates(\"image_id\").reset_index(drop=True)\n",
        "\n",
        "wide = train_long.pivot_table(index=\"image_id\", columns=\"target_name\", values=\"target\", aggfunc=\"first\").reset_index()\n",
        "train_wide = meta.merge(wide, on=\"image_id\", how=\"inner\")\n",
        "\n",
        "TARGETS = [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\",\"GDM_g\",\"Dry_Total_g\"]\n",
        "for t in TARGETS:\n",
        "    if t not in train_wide.columns: train_wide[t] = np.nan\n",
        "\n",
        "# Learn 3 components; derive 2 (stored for eval only)\n",
        "train_wide[\"Der_Dry_Total_g\"] = train_wide[\"Dry_Green_g\"] + train_wide[\"Dry_Dead_g\"] + train_wide[\"Dry_Clover_g\"]\n",
        "train_wide[\"Der_GDM_g\"] = train_wide[\"Dry_Green_g\"] + train_wide[\"Dry_Clover_g\"]\n",
        "\n",
        "#  date features for grouping (no model usage unless test has them)\n",
        "if \"Sampling_Date\" in train_wide.columns:\n",
        "    d = pd.to_datetime(train_wide[\"Sampling_Date\"], errors=\"coerce\")\n",
        "    train_wide[\"month\"] = d.dt.month.fillna(0).astype(int)\n",
        "\n",
        "print(\"train_wide shape:\", train_wide.shape)\n",
        "print(\"Missing rate (components):\", train_wide[[\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\"]].isna().mean().to_dict())\n",
        "\n",
        "# Quick constraint check\n",
        "err_total = (train_wide[\"Dry_Total_g\"] - train_wide[\"Der_Dry_Total_g\"]).abs()\n",
        "err_gdm   = (train_wide[\"GDM_g\"] - train_wide[\"Der_GDM_g\"]).abs()\n",
        "print(\"Mean abs constraint error |Total|:\", float(err_total.mean(skipna=True)))\n",
        "print(\"Mean abs constraint error |GDM|  :\", float(err_gdm.mean(skipna=True)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUW6tbekw0c5",
        "outputId": "41d9c1ba-e672-4fc0-b98d-486ce2b1f0df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_wide shape: (357, 15)\n",
            "Missing rate (components): {'Dry_Green_g': 0.0, 'Dry_Dead_g': 0.0, 'Dry_Clover_g': 0.0}\n",
            "Mean abs constraint error |Total|: 0.0008784313725504181\n",
            "Mean abs constraint error |GDM|  : 1.484593837576958e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 4 5-fold split + weighted R² (global)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "assert \"train_wide\" in globals(), \"Run Block 3 first.\"\n",
        "\n",
        "WEIGHTS = {\"Dry_Green_g\":0.1,\"Dry_Dead_g\":0.1,\"Dry_Clover_g\":0.1,\"GDM_g\":0.2,\"Dry_Total_g\":0.5}\n",
        "\n",
        "#  stronger if State+month exists, else image_id\n",
        "if (\"State\" in train_wide.columns) and (\"month\" in train_wide.columns) and (train_wide[\"month\"].nunique() > 1):\n",
        "    train_wide[\"group_key\"] = train_wide[\"State\"].astype(str) + \"_\" + train_wide[\"month\"].astype(str)\n",
        "else:\n",
        "    train_wide[\"group_key\"] = train_wide[\"image_id\"].astype(str)\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "train_wide[\"fold\"] = -1\n",
        "for f, (_, va) in enumerate(gkf.split(train_wide, groups=train_wide[\"group_key\"])):\n",
        "    train_wide.loc[va, \"fold\"] = f\n",
        "\n",
        "print(\"Fold counts:\", train_wide[\"fold\"].value_counts().sort_index().to_dict())\n",
        "print(\"Using group_key:\", \"State_month\" if \"State\" in train_wide.columns and \"month\" in train_wide.columns else \"image_id\")\n",
        "\n",
        "def weighted_r2_long(y_true_long, y_pred_long, w_long):\n",
        "    y_true_long = np.asarray(y_true_long, float)\n",
        "    y_pred_long = np.asarray(y_pred_long, float)\n",
        "    w_long = np.asarray(w_long, float)\n",
        "    w_long = np.clip(w_long, 1e-12, None)\n",
        "    y_bar = np.sum(w_long * y_true_long) / np.sum(w_long)\n",
        "    ss_res = np.sum(w_long * (y_true_long - y_pred_long) ** 2)\n",
        "    ss_tot = np.sum(w_long * (y_true_long - y_bar) ** 2)\n",
        "    return 1.0 - ss_res / max(ss_tot, 1e-12)\n",
        "\n",
        "def wide_to_long_for_metric(df_wide, pred_prefix=\"pred_\"):\n",
        "    # expects either true cols or pred_ cols; uses derived logic for totals/GDM if prefix provided\n",
        "    tG, tD, tC = pred_prefix+\"Dry_Green_g\", pred_prefix+\"Dry_Dead_g\", pred_prefix+\"Dry_Clover_g\"\n",
        "    out = []\n",
        "    for t in [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\"]:\n",
        "        out.append((t, df_wide[t].values, df_wide[pred_prefix+t].values, WEIGHTS[t]))\n",
        "    pred_total = df_wide[tG].values + df_wide[tD].values + df_wide[tC].values\n",
        "    pred_gdm   = df_wide[tG].values + df_wide[tC].values\n",
        "    out.append((\"Dry_Total_g\", df_wide[\"Dry_Total_g\"].values, pred_total, WEIGHTS[\"Dry_Total_g\"]))\n",
        "    out.append((\"GDM_g\", df_wide[\"GDM_g\"].values, pred_gdm, WEIGHTS[\"GDM_g\"]))\n",
        "    y_true = np.concatenate([a[1] for a in out]); y_pred = np.concatenate([a[2] for a in out])\n",
        "    w = np.concatenate([np.full(len(df_wide), a[3]) for a in out])\n",
        "    return y_true, y_pred, w\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZza8co4xOxI",
        "outputId": "a52a23d2-a39b-4e6f-b4f7-acd92270d1cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold counts: {0: 74, 1: 66, 2: 75, 3: 67, 4: 75}\n",
            "Using group_key: State_month\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH v2: remove RandomResizedCrop (albumentations API mismatch), use stable crop pipeline\n",
        "import cv2, torch, numpy as np, albumentations as A\n",
        "from torch.utils.data import Dataset\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "print(\"albumentations version:\", A.__version__)\n",
        "IMG_SIZE = 384\n",
        "Y_COLS = [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\"]\n",
        "\n",
        "def get_tfms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.RandomScale(scale_limit=0.25, p=0.8),\n",
        "            A.PadIfNeeded(min_height=IMG_SIZE, min_width=IMG_SIZE,\n",
        "                          border_mode=cv2.BORDER_REFLECT_101, p=1.0),\n",
        "            A.RandomCrop(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.2),\n",
        "            A.RandomRotate90(p=0.2),\n",
        "            A.RandomBrightnessContrast(p=0.25),\n",
        "            A.Normalize(), ToTensorV2()\n",
        "        ])\n",
        "    return A.Compose([A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.Normalize(), ToTensorV2()])\n",
        "\n",
        "class PastureDS(Dataset):\n",
        "    def __init__(self, df, train=True):\n",
        "        self.df = df.reset_index(drop=True); self.tfms = get_tfms(train)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        fp = str(BASE_DIR / r[\"image_path\"])\n",
        "        img = cv2.cvtColor(cv2.imread(fp), cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfms(image=img)[\"image\"]\n",
        "        y = torch.tensor(r[Y_COLS].values.astype(np.float32))\n",
        "        return x, y, r[\"image_id\"]\n",
        "\n",
        "# smoke test\n",
        "ds = PastureDS(train_wide.sample(4, random_state=1947), train=True)\n",
        "x, y, iid = ds[0]\n",
        "print(\"x:\", tuple(x.shape), \"y:\", y.tolist(), \"image_id:\", iid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Zcmtw42l9y",
        "outputId": "1c689884-c0b9-493c-ef39-a8f7ecfd9363"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "albumentations version: 2.0.8\n",
            "x: (3, 384, 384) y: [6.599999904632568, 0.4000000059604645, 0.5] image_id: ID146920896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 6 (<=50 lines): install timm + loaders + 3-output model + derive helper\n",
        "!pip -q install timm\n",
        "\n",
        "import os, torch, torch.nn as nn, numpy as np, timm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "assert \"train_wide\" in globals() and \"PastureDS\" in globals(), \"Run Blocks 1–5 first.\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH = 16; WORKERS = os.cpu_count() or 2\n",
        "\n",
        "def make_loaders(fold):\n",
        "    tr = train_wide[train_wide.fold != fold].reset_index(drop=True)\n",
        "    va = train_wide[train_wide.fold == fold].reset_index(drop=True)\n",
        "    dl_tr = DataLoader(PastureDS(tr, True), batch_size=BATCH, shuffle=True,  num_workers=WORKERS, pin_memory=True)\n",
        "    dl_va = DataLoader(PastureDS(va, False), batch_size=BATCH, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    return dl_tr, dl_va, va\n",
        "\n",
        "class ImgReg3(nn.Module):\n",
        "    def __init__(self, backbone, pretrained=True, drop=0.2):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n",
        "        d = self.backbone.num_features\n",
        "        self.head = nn.Sequential(nn.LayerNorm(d), nn.Dropout(drop), nn.Linear(d,256), nn.GELU(),\n",
        "                                  nn.Dropout(drop), nn.Linear(256,3))\n",
        "    def forward(self, x): return self.head(self.backbone(x))\n",
        "\n",
        "@torch.no_grad()\n",
        "def derive5(pred3):\n",
        "    g, d, c = pred3[:,0], pred3[:,1], pred3[:,2]\n",
        "    return {\"Dry_Green_g\":g, \"Dry_Dead_g\":d, \"Dry_Clover_g\":c, \"Dry_Total_g\":g+d+c, \"GDM_g\":g+c}\n",
        "\n",
        "print(\"device:\", device, \"| batch:\", BATCH, \"| workers:\", WORKERS)\n",
        "dl_tr, dl_va, va_df = make_loaders(0)\n",
        "xb, yb, _ = next(iter(dl_tr))\n",
        "print(\"batch x:\", tuple(xb.shape), \"batch y:\", tuple(yb.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvu8KiEL28OV",
        "outputId": "fb6d85b9-4f2d-4782-d897-c917d7b63b31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda | batch: 16 | workers: 12\n",
            "batch x: (16, 3, 384, 384) batch y: (16, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 7 (<=50 lines): weighted loss (incl. derived) + weighted R² eval\n",
        "import numpy as np, torch\n",
        "\n",
        "assert \"WEIGHTS\" in globals(), \"WEIGHTS not found (Block 2).\"\n",
        "\n",
        "W = WEIGHTS  # alias\n",
        "\n",
        "def weighted_loss_from_pred3(pred3, y3_true):\n",
        "    # pred3,y3_true: (B,3) => targets: Green,Dead,Clover\n",
        "    pg, pd, pc = pred3[:,0], pred3[:,1], pred3[:,2]\n",
        "    tg, td, tc = y3_true[:,0], y3_true[:,1], y3_true[:,2]\n",
        "    p_total, t_total = pg+pd+pc, tg+td+tc\n",
        "    p_gdm,   t_gdm   = pg+pc,    tg+tc\n",
        "    loss = 0.0\n",
        "    loss += W[\"Dry_Green_g\"]  * torch.mean((pg - tg) ** 2)\n",
        "    loss += W[\"Dry_Dead_g\"]   * torch.mean((pd - td) ** 2)\n",
        "    loss += W[\"Dry_Clover_g\"] * torch.mean((pc - tc) ** 2)\n",
        "    loss += W[\"Dry_Total_g\"]  * torch.mean((p_total - t_total) ** 2)\n",
        "    loss += W[\"GDM_g\"]        * torch.mean((p_gdm - t_gdm) ** 2)\n",
        "    return loss\n",
        "\n",
        "def weighted_r2(y_true, y_pred, w):\n",
        "    y_true, y_pred, w = np.asarray(y_true,float), np.asarray(y_pred,float), np.asarray(w,float)\n",
        "    w = np.clip(w, 1e-12, None)\n",
        "    ybar = (w*y_true).sum() / w.sum()\n",
        "    ss_res = (w*(y_true-y_pred)**2).sum()\n",
        "    ss_tot = (w*(y_true-ybar)**2).sum()\n",
        "    return 1.0 - ss_res / max(ss_tot, 1e-12)\n",
        "\n",
        "def eval_weighted_r2_from_pred3(y3_true, pred3):\n",
        "    # y3_true,pred3: (N,3); returns competition-like weighted R² across 5 targets\n",
        "    yg, yd, yc = y3_true[:,0], y3_true[:,1], y3_true[:,2]\n",
        "    pg, pd, pc = pred3[:,0], pred3[:,1], pred3[:,2]\n",
        "    y = np.concatenate([yg, yd, yc, (yg+yd+yc), (yg+yc)])\n",
        "    p = np.concatenate([pg, pd, pc, (pg+pd+pc), (pg+pc)])\n",
        "    w = np.concatenate([\n",
        "        np.full(len(yg), W[\"Dry_Green_g\"]),\n",
        "        np.full(len(yd), W[\"Dry_Dead_g\"]),\n",
        "        np.full(len(yc), W[\"Dry_Clover_g\"]),\n",
        "        np.full(len(yg), W[\"Dry_Total_g\"]),\n",
        "        np.full(len(yg), W[\"GDM_g\"]),\n",
        "    ])\n",
        "    return weighted_r2(y, p, w)\n",
        "\n",
        "print(\"Weighted loss + eval ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1xrzcVU3T_a",
        "outputId": "b25f0ea6-6c16-4b76-e3a5-9cbad3ec98e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted loss + eval ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH v4: make IMG_SIZE divisible by patch size 14 (DINOv2/SigLIP patch14)\n",
        "IMG_SIZE = 392  # 14 * 28; replaces 384\n",
        "\n",
        "# update transforms + dataset to use new IMG_SIZE\n",
        "def get_tfms(train=True):\n",
        "    import albumentations as A\n",
        "    from albumentations.pytorch import ToTensorV2\n",
        "    import cv2\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.RandomScale(scale_limit=0.25, p=0.8),\n",
        "            A.PadIfNeeded(min_height=IMG_SIZE, min_width=IMG_SIZE, border_mode=cv2.BORDER_REFLECT_101, p=1.0),\n",
        "            A.RandomCrop(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.2),\n",
        "            A.RandomRotate90(p=0.2),\n",
        "            A.RandomBrightnessContrast(p=0.25),\n",
        "            A.Normalize(), ToTensorV2()\n",
        "        ])\n",
        "    return A.Compose([A.Resize(height=IMG_SIZE, width=IMG_SIZE), A.Normalize(), ToTensorV2()])\n",
        "\n",
        "# Recreate loaders and re-smoke-test model\n",
        "dl_tr, _, _ = make_loaders(0)\n",
        "xb, yb, _ = next(iter(dl_tr))\n",
        "m = ImgReg3(BACKBONE_A, pretrained=True).to(device).eval()\n",
        "with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "    out = m(xb.to(device))\n",
        "print(\"OK -> IMG_SIZE:\", IMG_SIZE, \"batch:\", tuple(xb.shape), \"out:\", tuple(out.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skVhooSa5wZO",
        "outputId": "62d7ef50-6a01-4d0f-e807-978af0956b11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK -> IMG_SIZE: 392 batch: (16, 3, 392, 392) out: (16, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 8 (<=50 lines): Train ModelA (DINOv2) 1 fold (freeze->partial FT) + save best + OOF\n",
        "import torch, numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "FOLD = 0\n",
        "dl_tr, dl_va, va_df = make_loaders(FOLD)\n",
        "BACKBONE_A = globals().get(\"BACKBONE_A\", \"vit_giant_patch14_dinov2\")\n",
        "print(\"Train ModelA:\", BACKBONE_A, \"| IMG_SIZE:\", IMG_SIZE)\n",
        "\n",
        "model = ImgReg3(BACKBONE_A, pretrained=True).to(device)\n",
        "ckpt_dir = RUN_DIR/\"checkpoints\"/\"modelA_dinov2\"/f\"fold_{FOLD}\"; ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "best_path = ckpt_dir/\"best.pt\"; best_r2 = -1e9\n",
        "\n",
        "def set_trainable(phase2=False, unfreeze_last=2):\n",
        "    for p in model.backbone.parameters(): p.requires_grad = False\n",
        "    for p in model.head.parameters(): p.requires_grad = True\n",
        "    if phase2 and hasattr(model.backbone, \"blocks\"):\n",
        "        for b in model.backbone.blocks[-unfreeze_last:]:\n",
        "            for p in b.parameters(): p.requires_grad = True\n",
        "\n",
        "def run_val():\n",
        "    model.eval(); P=[]; Y=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y,_ in dl_va:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "                p = model(x.to(device))\n",
        "            P.append(p.float().cpu().numpy()); Y.append(y.numpy())\n",
        "    return eval_weighted_r2_from_pred3(np.concatenate(Y), np.concatenate(P)), np.concatenate(P)\n",
        "\n",
        "def run_train(opt):\n",
        "    model.train()\n",
        "    for x,y,_ in tqdm(dl_tr, leave=False):\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "            p = model(x); loss = weighted_loss_from_pred3(p, y)\n",
        "        opt.zero_grad(set_to_none=True); scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "\n",
        "# Phase A1\n",
        "set_trainable(False); opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=2e-3, weight_decay=1e-4)\n",
        "for ep in range(2):\n",
        "    run_train(opt); r2,_ = run_val(); print(f\"A1 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), best_path)\n",
        "\n",
        "# Phase A2\n",
        "set_trainable(True, unfreeze_last=2); opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
        "for ep in range(4):\n",
        "    run_train(opt); r2,_ = run_val(); print(f\"A2 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), best_path)\n",
        "\n",
        "# OOF save\n",
        "model.load_state_dict(torch.load(best_path, map_location=device)); r2, P = run_val()\n",
        "np.savez(RUN_DIR/\"oof\"/f\"oof_modelA_fold{FOLD}.npz\", image_id=va_df[\"image_id\"].values, pred3=P)\n",
        "print(\"Best val_wR2:\", best_r2, \"| OOF wR2:\", r2, \"| saved:\", best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLVZUUTY6Fpt",
        "outputId": "520be11a-7a3d-4152-bb46-fb1f94db0941"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train ModelA: vit_giant_patch14_dinov2 | IMG_SIZE: 392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 ep1 val_wR2=0.18503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 ep2 val_wR2=0.46867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep1 val_wR2=0.21187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep2 val_wR2=0.42753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep3 val_wR2=0.53017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep4 val_wR2=0.52143\n",
            "Best val_wR2: 0.5301685070125199 | OOF wR2: 0.5301685070125199 | saved: /content/drive/MyDrive/CSIRO/runs/run_001/checkpoints/modelA_dinov2/fold_0/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 9 (<=50 lines): Train ModelB (SigLIP) 1 fold (freeze->partial FT) + save best + OOF\n",
        "import torch, numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "FOLD = 0\n",
        "dl_tr, dl_va, va_df = make_loaders(FOLD)\n",
        "\n",
        "siglip = [m for m in timm.list_models() if \"siglip\" in m]\n",
        "pref = [\"vit_so400m_patch14_siglip_384\",\"vit_so400m_patch14_siglip\",\"vit_base_patch16_siglip_384\"]\n",
        "BACKBONE_B = next((p for p in pref if p in siglip), siglip[0])\n",
        "print(\"Train ModelB:\", BACKBONE_B, \"| IMG_SIZE:\", IMG_SIZE)\n",
        "\n",
        "model = ImgReg3(BACKBONE_B, pretrained=True).to(device)\n",
        "ckpt_dir = RUN_DIR/\"checkpoints\"/\"modelB_siglip\"/f\"fold_{FOLD}\"; ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "best_path = ckpt_dir/\"best.pt\"; best_r2 = -1e9\n",
        "\n",
        "def set_trainable(phase2=False, unfreeze_last=2):\n",
        "    for p in model.backbone.parameters(): p.requires_grad = False\n",
        "    for p in model.head.parameters(): p.requires_grad = True\n",
        "    if phase2 and hasattr(model.backbone, \"blocks\"):\n",
        "        for b in model.backbone.blocks[-unfreeze_last:]:\n",
        "            for p in b.parameters(): p.requires_grad = True\n",
        "\n",
        "def val():\n",
        "    model.eval(); P=[]; Y=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y,_ in dl_va:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "                p = model(x.to(device))\n",
        "            P.append(p.float().cpu().numpy()); Y.append(y.numpy())\n",
        "    P,Y = np.concatenate(P), np.concatenate(Y)\n",
        "    return eval_weighted_r2_from_pred3(Y, P), P\n",
        "\n",
        "def train_epoch(opt):\n",
        "    model.train()\n",
        "    for x,y,_ in tqdm(dl_tr, leave=False):\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "            p = model(x); loss = weighted_loss_from_pred3(p, y)\n",
        "        opt.zero_grad(set_to_none=True); scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "\n",
        "# Phase B1\n",
        "set_trainable(False); opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=2e-3, weight_decay=1e-4)\n",
        "for ep in range(2):\n",
        "    train_epoch(opt); r2,_ = val(); print(f\"B1 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), best_path)\n",
        "\n",
        "# Phase B2\n",
        "set_trainable(True, unfreeze_last=2); opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
        "for ep in range(4):\n",
        "    train_epoch(opt); r2,_ = val(); print(f\"B2 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), best_path)\n",
        "\n",
        "model.load_state_dict(torch.load(best_path, map_location=device)); r2, P = val()\n",
        "np.savez(RUN_DIR/\"oof\"/f\"oof_modelB_fold{FOLD}.npz\", image_id=va_df[\"image_id\"].values, pred3=P)\n",
        "print(\"Best val_wR2:\", best_r2, \"| OOF wR2:\", r2, \"| saved:\", best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "d6a2ae9bb8f44693bb2c2670a9156b39",
            "e892bf9da0964e01a231afdf83d2eb85",
            "6e13feb8bd3a4699815c77b3a60b6573",
            "9d2f8e0de6b54e0291b5f0874aa15c69",
            "13aef4d8c5bb4c1bb5647dbe07819c61",
            "677bf4adcae94088a49542435935fe81",
            "119d9edc776d4e4bb2177b98467794ab",
            "dca9092a6bfc4247a8689daf1d974a86",
            "f174b752098647c69ef3f98167226a23",
            "1749a36621674a8690ed9d7ee50e0b7f",
            "0bf8707f80ca40d09028ab0b8b42f4db"
          ]
        },
        "id": "Dyoujkc4699z",
        "outputId": "de4471dd-90c6-4a1d-9400-b24413dc11cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train ModelB: vit_so400m_patch14_siglip_384 | IMG_SIZE: 392\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6a2ae9bb8f44693bb2c2670a9156b39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B1 ep1 val_wR2=0.12675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B1 ep2 val_wR2=0.18123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B2 ep1 val_wR2=0.11791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B2 ep2 val_wR2=0.32513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B2 ep3 val_wR2=-0.00008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B2 ep4 val_wR2=0.07684\n",
            "Best val_wR2: 0.3251272394609881 | OOF wR2: 0.3251272394609881 | saved: /content/drive/MyDrive/CSIRO/runs/run_001/checkpoints/modelB_siglip/fold_0/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 10 (<=50 lines): OOF health checks (fold0) + ensemble weight suggestion\n",
        "import numpy as np\n",
        "\n",
        "FOLD=0\n",
        "a = np.load(RUN_DIR/\"oof\"/f\"oof_modelA_fold{FOLD}.npz\", allow_pickle=True)\n",
        "b = np.load(RUN_DIR/\"oof\"/f\"oof_modelB_fold{FOLD}.npz\", allow_pickle=True)\n",
        "id_a, pA = a[\"image_id\"], a[\"pred3\"]\n",
        "id_b, pB = b[\"image_id\"], b[\"pred3\"]\n",
        "assert np.all(id_a==id_b), \"OOF image_id mismatch between models.\"\n",
        "\n",
        "va = train_wide[train_wide.fold==FOLD].reset_index(drop=True)\n",
        "Y = va[[\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\"]].values.astype(np.float32)\n",
        "\n",
        "r2A = eval_weighted_r2_from_pred3(Y, pA)\n",
        "r2B = eval_weighted_r2_from_pred3(Y, pB)\n",
        "\n",
        "# try a few ensemble weights: pred = w*A + (1-w)*B\n",
        "ws = np.linspace(0,1,11)\n",
        "r2s = []\n",
        "for w in ws:\n",
        "    p = w*pA + (1-w)*pB\n",
        "    r2s.append(eval_weighted_r2_from_pred3(Y, p))\n",
        "best_i = int(np.argmax(r2s))\n",
        "print(\"Fold0 wR2: A=\", round(r2A,5), \" B=\", round(r2B,5))\n",
        "print(\"Ensemble grid best: w(A)=\", float(ws[best_i]), \" wR2=\", float(r2s[best_i]))\n",
        "\n",
        "# per-target debug metrics (derived totals included)\n",
        "def per_target_rmse_mae(y3, p3):\n",
        "    yg,yd,yc = y3[:,0],y3[:,1],y3[:,2]; pg,pd,pc = p3[:,0],p3[:,1],p3[:,2]\n",
        "    Y5 = {\"Dry_Green_g\":yg,\"Dry_Dead_g\":yd,\"Dry_Clover_g\":yc,\"Dry_Total_g\":yg+yd+yc,\"GDM_g\":yg+yc}\n",
        "    P5 = {\"Dry_Green_g\":pg,\"Dry_Dead_g\":pd,\"Dry_Clover_g\":pc,\"Dry_Total_g\":pg+pd+pc,\"GDM_g\":pg+pc}\n",
        "    out={}\n",
        "    for k in Y5:\n",
        "        e = P5[k]-Y5[k]\n",
        "        out[k] = (float(np.sqrt(np.mean(e**2))), float(np.mean(np.abs(e))))\n",
        "    return out\n",
        "\n",
        "dbgA = per_target_rmse_mae(Y, pA)\n",
        "dbgB = per_target_rmse_mae(Y, pB)\n",
        "print(\"\\nRMSE, MAE (A):\", dbgA)\n",
        "print(\"RMSE, MAE (B):\", dbgB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IhQut9u76Ia",
        "outputId": "ad611500-2139-489b-893a-d87c3c9809d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0 wR2: A= 0.53017  B= 0.32513\n",
            "Ensemble grid best: w(A)= 1.0  wR2= 0.5301685070125199\n",
            "\n",
            "RMSE, MAE (A): {'Dry_Green_g': (23.59312629699707, 18.4628963470459), 'Dry_Dead_g': (15.26081371307373, 11.639562606811523), 'Dry_Clover_g': (17.01992416381836, 10.674093246459961), 'Dry_Total_g': (25.13693618774414, 17.048023223876953), 'GDM_g': (19.574140548706055, 13.56136703491211)}\n",
            "RMSE, MAE (B): {'Dry_Green_g': (26.01597785949707, 19.010896682739258), 'Dry_Dead_g': (16.194494247436523, 12.09109878540039), 'Dry_Clover_g': (18.8719425201416, 12.040096282958984), 'Dry_Total_g': (31.0206241607666, 21.07330894470215), 'GDM_g': (23.26336097717285, 16.551250457763672)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH: Train only FOLD=4 with local checkpoint, then copy to Drive (<100 lines)\n",
        "import os, shutil, torch, numpy as np\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "FOLD = 4\n",
        "dl_tr, dl_va, va_df = make_loaders(FOLD)\n",
        "BACKBONE_A = globals().get(\"BACKBONE_A\", \"vit_giant_patch14_dinov2\")\n",
        "print(\"Training fold\", FOLD, \"| backbone:\", BACKBONE_A, \"| IMG_SIZE:\", IMG_SIZE)\n",
        "\n",
        "# local temp paths (reliable)\n",
        "LOCAL_DIR = Path(f\"/content/tmp_modelA_fold{FOLD}\")\n",
        "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "local_best = LOCAL_DIR / \"best.pt\"\n",
        "\n",
        "# drive paths (final destination)\n",
        "drive_ckpt_dir = RUN_DIR/\"checkpoints\"/\"modelA_dinov2\"/f\"fold_{FOLD}\"\n",
        "drive_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "drive_best = drive_ckpt_dir / \"best.pt\"\n",
        "drive_oof  = RUN_DIR/\"oof\"/f\"oof_modelA_fold{FOLD}.npz\"\n",
        "\n",
        "model = ImgReg3(BACKBONE_A, pretrained=True).to(device)\n",
        "torch.save(model.state_dict(), local_best)  # guarantee exists locally\n",
        "best_r2 = -1e9\n",
        "\n",
        "def set_trainable(phase2=False, unfreeze_last=2):\n",
        "    for p in model.backbone.parameters(): p.requires_grad = False\n",
        "    for p in model.head.parameters(): p.requires_grad = True\n",
        "    if phase2 and hasattr(model.backbone, \"blocks\"):\n",
        "        for b in model.backbone.blocks[-unfreeze_last:]:\n",
        "            for p in b.parameters(): p.requires_grad = True\n",
        "\n",
        "def val():\n",
        "    model.eval(); P=[]; Y=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y,_ in dl_va:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "                p = model(x.to(device))\n",
        "            P.append(p.float().cpu().numpy()); Y.append(y.numpy())\n",
        "    P,Y = np.concatenate(P), np.concatenate(Y)\n",
        "    return eval_weighted_r2_from_pred3(Y, P), P\n",
        "\n",
        "def train_epoch(opt):\n",
        "    model.train()\n",
        "    for x,y,_ in tqdm(dl_tr, leave=False):\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "            p = model(x); loss = weighted_loss_from_pred3(p, y)\n",
        "        if not torch.isfinite(loss): continue\n",
        "        opt.zero_grad(set_to_none=True); scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "\n",
        "# Phase A1\n",
        "set_trainable(False)\n",
        "opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=2e-3, weight_decay=1e-4)\n",
        "for ep in range(2):\n",
        "    train_epoch(opt); r2,_ = val()\n",
        "    print(f\"A1 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if np.isfinite(r2) and r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), local_best)\n",
        "\n",
        "# Phase A2\n",
        "set_trainable(True, unfreeze_last=2)\n",
        "opt = torch.optim.AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
        "for ep in range(4):\n",
        "    train_epoch(opt); r2,_ = val()\n",
        "    print(f\"A2 ep{ep+1} val_wR2={r2:.5f}\")\n",
        "    if np.isfinite(r2) and r2 > best_r2: best_r2=r2; torch.save(model.state_dict(), local_best)\n",
        "\n",
        "# Final eval + save OOF locally\n",
        "model.load_state_dict(torch.load(local_best, map_location=device))\n",
        "r2, P = val()\n",
        "local_oof = LOCAL_DIR / \"oof.npz\"\n",
        "np.savez(local_oof, image_id=va_df[\"image_id\"].values, pred3=P)\n",
        "\n",
        "# Copy to Drive (atomic-ish)\n",
        "shutil.copyfile(local_best, drive_best)\n",
        "shutil.copyfile(local_oof, drive_oof)\n",
        "\n",
        "print(\"DONE fold\", FOLD, \"| best_wR2:\", round(best_r2,5), \"| final_wR2:\", round(r2,5))\n",
        "print(\"Saved to Drive:\", drive_best, \"and\", drive_oof)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvXYx_oi8S4c",
        "outputId": "88b9162c-55a4-470c-c068-ec2173281cea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 4 | backbone: vit_giant_patch14_dinov2 | IMG_SIZE: 392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 ep1 val_wR2=0.14549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 ep2 val_wR2=0.26539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep1 val_wR2=0.47167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep2 val_wR2=0.34288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep3 val_wR2=0.16961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2 ep4 val_wR2=0.22469\n",
            "DONE fold 4 | best_wR2: 0.47167 | final_wR2: 0.47167\n",
            "Saved to Drive: /content/drive/MyDrive/CSIRO/runs/run_001/checkpoints/modelA_dinov2/fold_4/best.pt and /content/drive/MyDrive/CSIRO/runs/run_001/oof/oof_modelA_fold4.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 12  Merge ModelA OOF (fold0-4) + overall weighted R²\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "oof_dir = RUN_DIR/\"oof\"\n",
        "preds = {}\n",
        "for f in range(5):\n",
        "    z = np.load(oof_dir/f\"oof_modelA_fold{f}.npz\", allow_pickle=True)\n",
        "    for iid, p in zip(z[\"image_id\"], z[\"pred3\"]):\n",
        "        preds[str(iid)] = p\n",
        "\n",
        "# align to full train_wide order\n",
        "ids = train_wide[\"image_id\"].astype(str).values\n",
        "P = np.stack([preds[i] for i in ids]).astype(np.float32)\n",
        "Y = train_wide[[\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\"]].values.astype(np.float32)\n",
        "\n",
        "oof_r2 = eval_weighted_r2_from_pred3(Y, P)\n",
        "print(\"ModelA overall OOF weighted R²:\", round(float(oof_r2), 6))\n",
        "\n",
        "# save merged OOF for later ensembling\n",
        "np.savez(oof_dir/\"oof_modelA_all.npz\", image_id=ids, pred3=P)\n",
        "print(\"Saved:\", oof_dir/\"oof_modelA_all.npz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZyEOnODNET",
        "outputId": "80455685-8557-47e9-d490-bf5544a815c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModelA overall OOF weighted R²: 0.582206\n",
            "Saved: /content/drive/MyDrive/CSIRO/runs/run_001/oof/oof_modelA_all.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 13 ModelA test inference (5-fold ensemble) + save preds_test_modelA\n",
        "import numpy as np, torch, cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "assert \"test_df\" in globals() and \"BACKBONE_A\" in globals(), \"Need Block 2 + patches (test_df, BACKBONE_A).\"\n",
        "\n",
        "test_imgs = test_df[[\"image_id\",\"image_path\"]].drop_duplicates(\"image_id\").reset_index(drop=True)\n",
        "\n",
        "class TestDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True); self.tfms = get_tfms(train=False)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        img = cv2.cvtColor(cv2.imread(str(BASE_DIR / r[\"image_path\"])), cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfms(image=img)[\"image\"]\n",
        "        return x, r[\"image_id\"]\n",
        "\n",
        "dl = DataLoader(TestDS(test_imgs), batch_size=BATCH, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "Psum = None\n",
        "for f in range(5):\n",
        "    ckpt = RUN_DIR/\"checkpoints\"/\"modelA_dinov2\"/f\"fold_{f}\"/\"best.pt\"\n",
        "    model = ImgReg3(BACKBONE_A, pretrained=False).to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "    Ps = []\n",
        "    with torch.no_grad():\n",
        "        for x,_ in dl:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "                p = model(x.to(device)).float().cpu().numpy()\n",
        "            Ps.append(p)\n",
        "    P = np.concatenate(Ps).astype(np.float32)\n",
        "    Psum = P if Psum is None else (Psum + P)\n",
        "\n",
        "P3 = (Psum / 5.0)\n",
        "P3 = np.clip(P3, 0.0, None)  # clamp negatives\n",
        "pg,pd,pc = P3[:,0],P3[:,1],P3[:,2]\n",
        "out = {\"image_id\": test_imgs[\"image_id\"].astype(str).values,\n",
        "       \"Dry_Green_g\":pg, \"Dry_Dead_g\":pd, \"Dry_Clover_g\":pc,\n",
        "       \"Dry_Total_g\":(pg+pd+pc), \"GDM_g\":(pg+pc)}\n",
        "\n",
        "np.savez(RUN_DIR/\"preds_test\"/\"preds_test_modelA.npz\", **out)\n",
        "print(\"Saved:\", RUN_DIR/\"preds_test\"/\"preds_test_modelA.npz\", \"| images:\", len(test_imgs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBgAB94PE2Vn",
        "outputId": "ff74ee5e-6886-44c5-a04d-0465a368bfe5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/CSIRO/runs/run_001/preds_test/preds_test_modelA.npz | images: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH Block 13  fix test image_id using image_path stem, then redo ModelA inference\n",
        "import numpy as np, torch, cv2\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"test_df shape:\", test_df.shape)\n",
        "test_df[\"image_key\"] = test_df[\"image_path\"].astype(str).apply(lambda p: Path(p).stem)\n",
        "test_imgs = test_df[[\"image_key\",\"image_path\"]].drop_duplicates(\"image_key\").reset_index(drop=True)\n",
        "print(\"Unique test images:\", len(test_imgs))\n",
        "\n",
        "class TestDS(Dataset):\n",
        "    def __init__(self, df): self.df=df.reset_index(drop=True); self.tfms=get_tfms(train=False)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r=self.df.iloc[i]\n",
        "        img=cv2.cvtColor(cv2.imread(str(BASE_DIR/r[\"image_path\"])), cv2.COLOR_BGR2RGB)\n",
        "        return self.tfms(image=img)[\"image\"], r[\"image_key\"]\n",
        "\n",
        "dl = DataLoader(TestDS(test_imgs), batch_size=BATCH, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "Psum=None\n",
        "for f in range(5):\n",
        "    ckpt = RUN_DIR/\"checkpoints\"/\"modelA_dinov2\"/f\"fold_{f}\"/\"best.pt\"\n",
        "    m = ImgReg3(BACKBONE_A, pretrained=False).to(device)\n",
        "    m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "    Ps=[]\n",
        "    with torch.no_grad():\n",
        "        for x,_ in dl:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "                Ps.append(m(x.to(device)).float().cpu().numpy())\n",
        "    P = np.concatenate(Ps).astype(np.float32)\n",
        "    Psum = P if Psum is None else (Psum + P)\n",
        "\n",
        "P3 = np.clip(Psum/5.0, 0.0, None)\n",
        "pg,pd,pc = P3[:,0],P3[:,1],P3[:,2]\n",
        "np.savez(RUN_DIR/\"preds_test\"/\"preds_test_modelA.npz\",\n",
        "         image_key=test_imgs[\"image_key\"].values.astype(str),\n",
        "         Dry_Green_g=pg, Dry_Dead_g=pd, Dry_Clover_g=pc,\n",
        "         Dry_Total_g=(pg+pd+pc), GDM_g=(pg+pc))\n",
        "print(\"Saved:\", RUN_DIR/\"preds_test\"/\"preds_test_modelA.npz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRFU_Dx0GOSP",
        "outputId": "c69e7ea9-96d9-4dac-cc5c-67a26233477a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_df shape: (5, 4)\n",
            "Unique test images: 1\n",
            "Saved: /content/drive/MyDrive/CSIRO/runs/run_001/preds_test/preds_test_modelA.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 14  Build submission.csv from test_df + preds_test_modelA.npz\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "pred_npz = np.load(RUN_DIR/\"preds_test\"/\"preds_test_modelA.npz\", allow_pickle=True)\n",
        "keys = pred_npz[\"image_key\"].astype(str)\n",
        "pred_map = {k:i for i,k in enumerate(keys)}\n",
        "\n",
        "# ensure test_df has image_key derived from image_path stem\n",
        "test_sub = test_df.copy()\n",
        "test_sub[\"image_key\"] = test_sub[\"image_path\"].astype(str).apply(lambda p: Path(p).stem)\n",
        "\n",
        "def get_pred(row):\n",
        "    i = pred_map[row[\"image_key\"]]\n",
        "    return float(pred_npz[row[\"target_name\"]][i])\n",
        "\n",
        "test_sub[\"target\"] = test_sub.apply(get_pred, axis=1)\n",
        "\n",
        "out = test_sub[[\"sample_id\",\"target\"]].copy()\n",
        "sub_path = RUN_DIR/\"submissions\"/\"submission_modelA.csv\"\n",
        "out.to_csv(sub_path, index=False)\n",
        "\n",
        "print(\"Saved submission:\", sub_path)\n",
        "print(out.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncbfvh2fHnAR",
        "outputId": "eb90c308-e2cb-4695-ba9e-6f8031344ff8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission: /content/drive/MyDrive/CSIRO/runs/run_001/submissions/submission_modelA.csv\n",
            "                    sample_id     target\n",
            "0  ID1001187975__Dry_Clover_g   6.400000\n",
            "1    ID1001187975__Dry_Dead_g  17.512501\n",
            "2   ID1001187975__Dry_Green_g  37.831249\n",
            "3   ID1001187975__Dry_Total_g  61.743752\n",
            "4         ID1001187975__GDM_g  44.231251\n"
          ]
        }
      ]
    }
  ]
}